{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea29893-b7bf-4d89-84f9-38642ec63ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "import collections\n",
    "import json\n",
    "import datasets\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, AutoModel, default_data_collator, get_scheduler\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from huggingface_hub import Repository, get_full_repo_name, notebook_login\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8f2a1e-540f-4c91-9049-8dbaaddca059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9317c6d78e80413b83298905b0201e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56daef9241444191ba8c373d4b2fcd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9064e25b0044b9aba5c31f745a187a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_44 split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72cd7710f6404973b6b2ec33fa206382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_54 split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = 'spoken_train-v1.1.json'\n",
    "test = 'spoken_test-v1.1.json'\n",
    "test_44 = 'spoken_test-v1.1_WER44.json'\n",
    "test_54 = 'spoken_test-v1.1_WER54.json'\n",
    "\n",
    "def preprocess(file):\n",
    "    S = []\n",
    "    with open(file,'r') as f: data = json.load(f)\n",
    "    for i in data['data']:\n",
    "        T = i['title']\n",
    "        for j in i['paragraphs']:\n",
    "            c = j['context']\n",
    "            for k in j['qas']:\n",
    "                l = {}\n",
    "                l['id'] = k['id']\n",
    "                l['context'] = c.strip()\n",
    "                l['title'] = T.strip()\n",
    "                l['question'] = k['question'].strip()\n",
    "                l['answers'] = {}\n",
    "                l['answers']['answer_start'] = [z['answer_start'] for z in k['answers']]\n",
    "                l['answers']['text'] = [z['text'] for z in k['answers']]\n",
    "                S.append(l)\n",
    "    Q = {'data':S}\n",
    "    output = 'out_'+file\n",
    "    with open(output,'w') as f: json.dump(Q,f)\n",
    "    return output\n",
    "\n",
    "train = preprocess(train)\n",
    "test = preprocess(test)\n",
    "test_44 = preprocess(test_44)\n",
    "test_54 = preprocess(test_54)\n",
    "dataset = datasets.load_dataset('json', data_files= {'train': train, 'test': test, 'test_44': test_44, 'test_54': test_54}, field='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65365543-e612-45ed-8fb0-17e4dcfab986",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\"rein5/bert-base-uncased-finetuned-spoken-squad\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rein5/bert-base-uncased-finetuned-spoken-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee292ec-1e6a-4d1a-9a05-aea4b3d99b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb43453c6a243b4b816749529805503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fnc(l):\n",
    "    q = [i.strip() for i in l['question']]\n",
    "    I = tokenizer(q, l['context'], max_length=384, stride=64, truncation='only_second',\n",
    "                  return_overflowing_tokens=True, return_offsets_mapping=True, padding='max_length')\n",
    "    Q = I.pop('offset_mapping')\n",
    "    S = I.pop('overflow_to_sample_mapping')\n",
    "    ans = l['answers']\n",
    "    first = []; last = []\n",
    "    for i, j in enumerate(Q):\n",
    "        index = S[i]\n",
    "        ans_ = ans[index]\n",
    "        first_chr = ans_['answer_start'][0]\n",
    "        end_char = ans_['answer_start'][0]+len(ans_[\"text\"][0])\n",
    "        z = 0\n",
    "        ID = I.sequence_ids(i)\n",
    "        while ID[z]!=1: z+=1\n",
    "        start = z\n",
    "        while ID[z]==1: z+=1\n",
    "        end = z-1\n",
    "        if j[start][0]>first_chr or j[end][1]<end_char:\n",
    "            first.append(0)\n",
    "            last.append(0)\n",
    "        else:\n",
    "            z = start\n",
    "            while z<=end and j[z][0]<=first_chr: z += 1\n",
    "            first.append(z-1)\n",
    "            z = end\n",
    "            while z>=start and j[z][1]>=end_char: z -= 1\n",
    "            last.append(z+1)\n",
    "    I['start_positions'] = first\n",
    "    I['end_positions'] = last\n",
    "    return I\n",
    "\n",
    "train_data = dataset['train'].map(fnc, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe9b510-5ef7-40c7-a0f7-21305dbad7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b097336b9e48808d56067a46f6beb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55935628840e4cc58a869227f6f690e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fc67714c574bb98aa8d0b28fa07567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fnc1(l):\n",
    "    q = [i.strip() for i in l['question']]\n",
    "    I = tokenizer(q, l['context'], max_length=384, stride=64, truncation='only_second',\n",
    "                  return_overflowing_tokens=True, return_offsets_mapping=True, padding='max_length')\n",
    "    r = []\n",
    "    S = I.pop('overflow_to_sample_mapping')\n",
    "    for i in range(len(I['input_ids'])):\n",
    "        idx = S[i]\n",
    "        r.append(l[\"id\"][idx])\n",
    "        ID = I.sequence_ids(i)\n",
    "        u = I['offset_mapping'][i]\n",
    "        I[\"offset_mapping\"][i] = [j if ID[k] == 1 else None for k, j in enumerate(u)]\n",
    "    I['example_id'] = r\n",
    "    return I\n",
    "\n",
    "val_data = dataset['test'].map(fnc1, batched=True, remove_columns=dataset['test'].column_names)\n",
    "test_44_data = dataset['test_44'].map(fnc1, batched=True, remove_columns=dataset['test_44'].column_names)\n",
    "test_54_data = dataset['test_54'].map(fnc1, batched=True, remove_columns=dataset['test_54'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4c79e0-553c-40c4-947c-9730e046d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = evaluate.load(\"squad\")\n",
    "def fnc2(x, y, f, l):\n",
    "    alpha = collections.defaultdict(list)\n",
    "    beta = []\n",
    "    for i, j in enumerate(f):\n",
    "        alpha[j[\"example_id\"]].append(i)\n",
    "    for k in tqdm(l):\n",
    "        id = k[\"id\"]\n",
    "        c = k[\"context\"]\n",
    "        res = []\n",
    "        for q in alpha[id]: \n",
    "            x_ = x[q]\n",
    "            y_ = y[q]\n",
    "            z_ = f[q][\"offset_mapping\"]\n",
    "            x_idx = np.argsort(x_)[-1:-21:-1].tolist()\n",
    "            y_idx = np.argsort(y_)[-1:-21:-1].tolist()\n",
    "            for x_idx_ in x_idx: \n",
    "                for y_idx_ in y_idx: \n",
    "                    if z_[x_idx_] is None or z_[y_idx_] is None: continue\n",
    "                    if y_idx_<x_idx_ or y_idx_-x_idx_+1>30: continue\n",
    "                    res_ = {\"text\":c[z_[x_idx_][0]:z_[y_idx_][1]], \"logit_score\":x_[x_idx_]+y_[y_idx_]}\n",
    "                    res.append(res_)\n",
    "        if len(res) > 0:\n",
    "            res__ = max(res, key=lambda x:x[\"logit_score\"])\n",
    "            beta.append({\"id\": id, \"prediction_text\": res__[\"text\"]})\n",
    "        else: \n",
    "            beta.append({\"id\": id, \"prediction_text\": \"\"})\n",
    "    ref = [{\"id\":p[\"id\"], \"answers\":p[\"answers\"]} for p in l]\n",
    "    return W.compute(predictions=beta, references=ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0acc1b3-9c10-44d3-880e-db1b41b1f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_format(\"torch\")\n",
    "val_ = val_data.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "val_.set_format(\"torch\")\n",
    "WER44_ = test_44_data.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "WER44_.set_format(\"torch\")\n",
    "WER54_ = test_54_data.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "WER54_.set_format(\"torch\")\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle = True, collate_fn=default_data_collator, batch_size=8)\n",
    "test_loader = DataLoader(val_, collate_fn=default_data_collator, batch_size=8)\n",
    "WER44_loader = DataLoader(WER44_, collate_fn=default_data_collator, batch_size=8)\n",
    "WER54_loader = DataLoader(WER54_, collate_fn=default_data_collator, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "942ffd8d-fc5d-400a-9d9e-cfaf8c37fef6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "100%|██████████| 678/678 [01:27<00:00,  7.77it/s]\n",
      "100%|██████████| 5351/5351 [00:07<00:00, 758.17it/s]\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "100%|██████████| 679/679 [01:25<00:00,  7.93it/s]\n",
      "100%|██████████| 5351/5351 [00:06<00:00, 778.57it/s]\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "100%|██████████| 679/679 [01:25<00:00,  7.92it/s]\n",
      "100%|██████████| 5351/5351 [00:07<00:00, 752.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************** RESULTS ****************************************\n",
      "Test Set  - Exact match: 62.08, F1 score: 72.70\n",
      "WER44 Set - Exact match: 39.06, F1 score: 53.93\n",
      "WER44 Set - Exact match: 27.85, F1 score: 41.57\n"
     ]
    }
   ],
   "source": [
    "def eval_(model, dataloader, dataset, dataset_, acc=None):\n",
    "    if not acc: \n",
    "        acc = Accelerator(mixed_precision='fp16')\n",
    "        model, dataloader = acc.prepare(model, dataloader)\n",
    "    model.eval()\n",
    "    S = []\n",
    "    E = []\n",
    "    for i in tqdm(dataloader):\n",
    "        with torch.no_grad(): \n",
    "            outputs = model(**i)\n",
    "        S.append(acc.gather(outputs.start_logits).cpu().numpy())\n",
    "        E.append(acc.gather(outputs.end_logits).cpu().numpy())\n",
    "    S = np.concatenate(S)\n",
    "    E = np.concatenate(E)\n",
    "    S = S[: len(dataset)]\n",
    "    E = E[: len(dataset)]\n",
    "    m = fnc2(S, E, dataset, dataset_)\n",
    "    return m\n",
    "\n",
    "def train_(model=model, train_loader=train_loader, test_loader=test_loader, epochs=1):\n",
    "    steps = epochs*len(train_dataloader)\n",
    "    acc = Accelerator(mixed_precision='fp16')\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "    model, optimizer, train_dataloader, eval_dataloader = acc.prepare(model, optimizer, train_loader, test_loader)\n",
    "    scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=steps)\n",
    "    pr = tqdm(range(steps))\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            acc.backward(loss)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            pr.update(1)\n",
    "        acc.print(\"Eval...\")\n",
    "        m__ = eval_(model, test_loader, val_data, dataset['validation'], acc)\n",
    "        print(f\"epoch {epoch}:\", m__)\n",
    "        acc.wait_for_everyone()\n",
    "        model_ = acc.unwrap_model(model)\n",
    "        model_.save_pretrained(\"bert-base-uncased-finetuned-spoken-squad\", save_function=acc.save)\n",
    "\n",
    "test__ = eval_(model, test_loader, val_data, dataset['test'])\n",
    "WER44__ = eval_(model, WER44_loader, test_44_data, dataset['test_44'])\n",
    "WER54__ = eval_(model, WER54_loader, test_54_data, dataset['test_54'])\n",
    "\n",
    "print(\"\\n**************************************** RESULTS ****************************************\")\n",
    "print('Test Set  - Exact match: {:.2f}, F1 score: {:.2f}'.format(test__['exact_match'],test__['f1']))\n",
    "print('WER44 Set - Exact match: {:.2f}, F1 score: {:.2f}'.format(WER44__['exact_match'],WER44__['f1']))\n",
    "print('WER44 Set - Exact match: {:.2f}, F1 score: {:.2f}'.format(WER54__['exact_match'],WER54__['f1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
